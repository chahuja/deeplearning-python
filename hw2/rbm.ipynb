{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive divergence for RBM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pickle as pkl\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Set random state to reproduce data\n",
    "rState = np.random.RandomState(212)\n",
    "# Load Data\n",
    "train = np.matrix(np.genfromtxt('digitstrain.txt', delimiter=','))\n",
    "rState.shuffle(train) ## Shuffle to improve convergence\n",
    "test = np.matrix(np.genfromtxt('digitstest.txt', delimiter=','))\n",
    "val = np.matrix(np.genfromtxt('digitsvalid.txt', delimiter=','))\n",
    "\n",
    "# Removing the class from the dataset\n",
    "\n",
    "_train = train[:,:-1]\n",
    "_test = test[:,:-1]\n",
    "_val = val[:,:-1]\n",
    "\n",
    "# and thresholding to {0,1}\n",
    "train = np.round(_train)\n",
    "test = np.round(_test)\n",
    "val = np.round(_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the image \n",
    "## The data is in row-major format\n",
    "def plot_image(train):\n",
    "  plt.imshow(train[0].reshape((28,28)))\n",
    "## The image is squeezed row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softplus(X):\n",
    "  return np.log(1+np.exp(X))\n",
    "\n",
    "def sigmoid(mat):\n",
    "  return 1./(1+ np.exp(-mat))\n",
    "\n",
    "def cross_entropy_loss(vec, gt):\n",
    "  ## take the average\n",
    "  return (-np.multiply(gt,np.log(vec)) - np.multiply(1-gt,np.log(1-vec))).sum()/vec.shape[1]\n",
    "\n",
    "def copy_list(a):\n",
    "  return [a[i].copy() for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualizing filters\n",
    "def vis(W, save_name):\n",
    "  dim = W.shape[1]\n",
    "  n_image_rows = int(np.ceil(np.sqrt(dim)))\n",
    "  n_image_cols = int(np.ceil(dim * 1.0/n_image_rows))\n",
    "  gs = gridspec.GridSpec(n_image_rows,n_image_cols,top=1., bottom=0., right=1., left=0., hspace=0., wspace=0.)\n",
    "  for g,count in zip(gs,range(int(dim))):\n",
    "    ax = plt.subplot(g)\n",
    "    ax.imshow(W[:,count].reshape((28,28)))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "  plt.savefig(save_name + '_vis.png')\n",
    "\n",
    "def plot_cce(model, save_name):  \n",
    "  train_plt = plt.plot(range(len(model.hist.train_loss)),model.hist.train_loss, 'r--', label='Train')\n",
    "  val_plt = plt.plot(range(len(model.hist.val_loss)),model.hist.val_loss, 'g-', label=\"Val\")\n",
    "  plt.xlabel('No. of Epochs')\n",
    "  plt.ylabel('mean(Entropy Loss)')\n",
    "  plt.savefig(save_name+'.png')\n",
    "\n",
    "def plot_err(model, save_name):  \n",
    "  train_plt = plt.plot(range(len(model.hist.train_loss)),model.hist.train_class_loss, 'r--', label='Train')\n",
    "  val_plt = plt.plot(range(len(model.hist.val_loss)),model.hist.val_class_loss, 'g-', label=\"Val\")\n",
    "  plt.xlabel('No. of Epochs')\n",
    "  plt.ylabel('Classification Error')\n",
    "  plt.savefig(save_name+'_err.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "  fl = open(filename,'wb')\n",
    "  pkl.dump(model,fl)\n",
    "  \n",
    "def save_weights(model, filename):\n",
    "  fl = open(filename, 'wb')\n",
    "  pkl.dump([model.W, model.b, model.c], fl)\n",
    "  \n",
    "def load_model(filename):\n",
    "  fl = open(filename, 'rb')\n",
    "  return pkl.load(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss History Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class history(object):\n",
    "  def __init__(self):\n",
    "    self.train_loss = list()\n",
    "    self.val_loss = list()\n",
    "    \n",
    "  def add(self,train_loss, val_loss):\n",
    "    self.train_loss.append(train_loss)\n",
    "    self.val_loss.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(object):\n",
    "  def __init__(self,graph):\n",
    "    self.graph = graph\n",
    "    self.hist = history()\n",
    "    \n",
    "    ## initialize the weights\n",
    "    high = np.sqrt(6.0/(sum(graph)))\n",
    "    low = -high\n",
    "    self.W = rState.uniform(low=low,high=high, size=(graph[1],graph[0])) # nXm\n",
    "    self.b = rState.uniform(low=low,high=high, size=(graph[1],1)) # nX1\n",
    "    self.c = rState.uniform(low=low,high=high, size=(graph[0],1)) # mX1\n",
    "    ## p(h=1|x) = sigm(Wx + b)\n",
    "    ## p(x=1|x) = sigm(W'h + c)\n",
    "    \n",
    "    self.W_optimal = copy_list(self.W)\n",
    "\n",
    "  def restore_optimal_weights(self):\n",
    "    self.W = copy_list(self.W_optimal)\n",
    "\n",
    "  def h(self,x):\n",
    "    return sigmoid(np.matmul(self.W, x) + self.b)\n",
    "  \n",
    "  def h_inv(self, h):\n",
    "    return sigmoid(np.matmul(self.W.T, h) + self.c)\n",
    "  \n",
    "  def sample(self,P):\n",
    "    return np.random.binomial(1,P,size=P.shape)\n",
    "  \n",
    "  ## MCMC chain to predict a {0,1} output\n",
    "  def MCMC(self, x, k):\n",
    "    ## create a MCMC chain\n",
    "    for i in range(k):\n",
    "      _h = self.h(x)\n",
    "      h = self.sample(_h)\n",
    "      _x = self.h_inv(h)\n",
    "      x = self.sample(_x)\n",
    "    \n",
    "    return x, self.h(x)\n",
    "  \n",
    "  ## MCMC chain to predict a continous output\n",
    "  def generation(self, x, k):\n",
    "    for i in range(k-1):\n",
    "      _h = self.h(x)\n",
    "      h = self.sample(_h)\n",
    "      _x = self.h_inv(h)\n",
    "      x = self.sample(_x)\n",
    "    \n",
    "    _h = self.h(x)\n",
    "    h = self.sample(_h)\n",
    "    _x = self.h_inv(h)\n",
    "    \n",
    "    return _x\n",
    "  \n",
    "  def train(self, x, k=1, lr=0.01):\n",
    "    x_cap, h_cap = self.MCMC(x,k)\n",
    "    _h = self.h(x)\n",
    "    gradW = np.matmul(_h, x.T) - np.matmul(h_cap,x_cap.T)\n",
    "    gradb = _h - h_cap\n",
    "    gradc = x - x_cap\n",
    "    \n",
    "    ## gradient updates applied on the weights\n",
    "    self.W += lr*gradW\n",
    "    self.b += lr*gradb\n",
    "    self.c += lr*gradc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_cross_entropy_loss(model, X):\n",
    "  x_gt = X.T\n",
    "  x_cap = model.h_inv(model.sample(model.h(model.sample(x_gt))))\n",
    "  l = cross_entropy_loss(x_cap, x_gt)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_train(args):\n",
    "  ## automatically creating a savename\n",
    "  save_name = \"%s_k%d_graph_%d\" %(args.save_dir, args.num_mcmc,args.graph[1])\n",
    "  save_name = os.path.join(args.save_dir, save_name)\n",
    "  \n",
    "  ## initilizing the rbm model\n",
    "  rbm = RBM(args.graph)\n",
    "  for count in tqdm(range(args.num_epochs)):\n",
    "    for i in range(train.shape[0]):\n",
    "      rbm.train(train[i].T, k=args.num_mcmc, lr=args.lr)\n",
    "    ## Calculation of cross entropy loss\n",
    "    train_loss = mean_cross_entropy_loss(rbm, train)\n",
    "    val_loss = mean_cross_entropy_loss(rbm, val)\n",
    "    ## Add loss to the history variable\n",
    "    rbm.hist.add(train_loss, val_loss)\n",
    "    print \"Epochs:%d Train Loss:%5f Test Loss:%5f\" % (count, train_loss, val_loss)\n",
    "    \n",
    "  ## plot and save images\n",
    "  plot_cce(model=rbm, save_name=save_name)\n",
    "  vis(W=rbm.W.T, save_name=save_name)\n",
    "  \n",
    "  ## save model\n",
    "  save_model(rbm, save_name + '_model.p')\n",
    "  ## save weights\n",
    "  save_weights(rbm, save_name + 'weights.p')\n",
    "  return rbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def digit_generation(model, filename='temp.png'):\n",
    "  X = np.random.uniform(size=train[0:100].T.shape)\n",
    "  ## binarize the input\n",
    "  X = np.round(X)\n",
    "  print np.max(X), np.min(X)\n",
    "  X_cap = model.generation(X,1000)\n",
    "  vis(X_cap,filename+'_gen.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--save_dir', type=str, default='save',\n",
    "                      help='directory to store checkpointed models')\n",
    "  parser.add_argument('--graph', type=int ,nargs='+', default=[784,100],\n",
    "                      help='Structure of the NN') \n",
    "  parser.add_argument('--prob', type=float, default=1,\n",
    "                      help='dropout coefficients')\n",
    "  parser.add_argument('--lam', type=float, default=0,\n",
    "                      help='regularizing coefficient')\n",
    "  parser.add_argument('--lr', type=float, default=0.01,\n",
    "                      help='learning rate')\n",
    "  parser.add_argument('--num_epochs', type=int, default=1, \n",
    "                      help='number of epochs')\n",
    "  parser.add_argument('--num_mcmc', type=int, default=1, \n",
    "                      help='number of mcmc iterations')\n",
    "  parser.add_argument('--seed', type=int, default=212, \n",
    "                      help='Random Seed')\n",
    "  args = parser.parse_args()\n",
    "  try:\n",
    "    os.makedirs(args.save_dir)\n",
    "  except:\n",
    "    pass\n",
    "  ## Train model\n",
    "  model = sgd_train(args)\n",
    "  \n",
    "  ## (c) Sample from images\n",
    "  save_name = \"%s_k%d_graph_%d\" %(args.save_dir, args.num_mcmc,args.graph[1])\n",
    "  save_name = os.path.join(args.save_dir, save_name)\n",
    "  digit_generation(model, filename=save_name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.argv=['train.py',\n",
    "         '--save_dir','model',\n",
    "         '--graph', '784', '100',\n",
    "         '--lr', '0.01',\n",
    "         '--num_epochs', '6',\n",
    "         '--num_mcmc', '5',\n",
    "         '--seed', '212']\n",
    "#if __name__==\"__main__\":\n",
    "model = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
